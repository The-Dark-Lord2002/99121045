{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c14c08-26d8-40cf-bc98-0e4e4f613f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numba import jit, prange\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2531f1ed-0678-40ff-9d9d-c64522ff5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def initialize_weights(x, y, input_len):\n",
    "    return np.random.rand(x, y, input_len)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def jaccard_distance(sample1, sample2):\n",
    "    intersection = np.sum(np.minimum(sample1, sample2))\n",
    "    union = np.sum(np.maximum(sample1, sample2)) + 1e-10  # Add a small value to avoid division by zero\n",
    "    return 1 - intersection / union\n",
    "\n",
    "@jit(nopython=True)\n",
    "def find_bmu(sample, weights):\n",
    "    x, y, input_len = weights.shape\n",
    "    min_dist = np.inf\n",
    "    bmu = (0, 0)\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            dist = jaccard_distance(sample, weights[i, j, :])\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                bmu = (i, j)\n",
    "    return bmu\n",
    "\n",
    "@jit(nopython=True)\n",
    "def neighborhood(center, radius, x, y):\n",
    "    influence = np.zeros((x, y))\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            distance = np.sqrt((i - center[0]) ** 2 + (j - center[1]) ** 2)\n",
    "            influence[i, j] = np.exp(-distance / (2 * (radius ** 2)))\n",
    "    return influence\n",
    "\n",
    "@jit(nopython=True)\n",
    "def update_weights(sample, weights, bmu, radius, learning_rate):\n",
    "    x, y, input_len = weights.shape\n",
    "    influence = neighborhood(bmu, radius, x, y)\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            weights[i, j, :] += influence[i, j] * learning_rate * (sample - weights[i, j, :])\n",
    "\n",
    "def train_som(data, x, y, input_len, sigma, learning_rate, num_iterations):\n",
    "    weights = initialize_weights(x, y, input_len)\n",
    "    initial_learning_rate = learning_rate\n",
    "    epsilon = 1e-10  # Small value to prevent division by zero\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        radius = sigma * np.exp(-iteration / (num_iterations / (np.log(sigma) + epsilon)))\n",
    "        learning_rate = initial_learning_rate * np.exp(-iteration / (num_iterations + epsilon))\n",
    "        \n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(process_sample, sample, weights, radius, learning_rate) for sample in data]\n",
    "            for future in futures:\n",
    "                weights = future.result()\n",
    "                \n",
    "        if (iteration % 10 == 0):\n",
    "            print(f\"iteration : {iteration}\")\n",
    "    return weights\n",
    "\n",
    "def process_sample(sample, weights, radius, learning_rate):\n",
    "    bmu = find_bmu(sample, weights)\n",
    "    update_weights(sample, weights, bmu, radius, learning_rate)\n",
    "    return weights\n",
    "\n",
    "def transform_som(data, weights):\n",
    "    transformed = np.zeros((data.shape[0], 2))\n",
    "    for i in prange(data.shape[0]):\n",
    "        transformed[i] = find_bmu(data[i], weights)\n",
    "    return transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1dc7e49-761d-4452-8fee-b757830c9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(-1, 32 * 32 * 3)\n",
    "x_test = x_test.reshape(-1, 32 * 32 * 3)\n",
    "\n",
    "# Select 3000 samples from the training set\n",
    "num_samples = 3000\n",
    "x_train = x_train[:num_samples]\n",
    "y_train = y_train[:num_samples]\n",
    "\n",
    "x_test = x_test[:500]\n",
    "y_test = y_test[:500]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "pca = PCA(n_components=50)  # Reduce to 50 components\n",
    "x_train_pca = pca.fit_transform(x_train)\n",
    "x_test_pca = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831a2564-1213-4e05-814a-d5d06d684472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOM parameters\n",
    "x = 10\n",
    "y = 10\n",
    "input_len = 32 * 32 * 3\n",
    "sigma = 1.0\n",
    "learning_rate = 0.5\n",
    "num_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4e49aa-1435-4271-a742-5942b11bec04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0\n",
      "iteration : 10\n",
      "iteration : 20\n",
      "iteration : 30\n",
      "iteration : 40\n",
      "iteration : 50\n",
      "iteration : 60\n",
      "iteration : 70\n",
      "iteration : 80\n",
      "iteration : 90\n",
      "Transformed Train Data: [[4. 8.]\n",
      " [3. 0.]\n",
      " [6. 0.]\n",
      " ...\n",
      " [0. 9.]\n",
      " [0. 2.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Train SOM\n",
    "weights = train_som(x_train, x, y, input_len, sigma, learning_rate, num_iterations)\n",
    "\n",
    "# Transform data\n",
    "transformed_train = transform_som(x_train, weights)\n",
    "\n",
    "print(\"Transformed Train Data:\", transformed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b51655-2c9b-4ab2-833b-5bfb32f15595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, weights, train_labels, x, y):\n",
    "    bmu_indices = transform_som(data, weights)\n",
    "    predicted_labels = np.zeros(bmu_indices.shape[0], dtype=train_labels.dtype)\n",
    "    \n",
    "    for idx, (i, j) in enumerate(bmu_indices):\n",
    "        closest_samples = []\n",
    "        for k in range(train_labels.shape[0]):  # Iterate over the number of training samples\n",
    "            train_bmu = find_bmu(x_train[k], weights)  # Use x_train[k] instead of data[k]\n",
    "            if train_bmu == (i, j):\n",
    "                closest_samples.append(train_labels[k])\n",
    "        if closest_samples:\n",
    "            closest_samples_flat = np.array(closest_samples).flatten()  # Flatten the list\n",
    "            predicted_labels[idx] = np.bincount(closest_samples_flat).argmax()\n",
    "        else:\n",
    "            predicted_labels[idx] = -1  # Assign a default label if no samples are found\n",
    "    \n",
    "    return predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fdb8b4-f967-4337-a70b-000c18de3e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "predicted_labels = predict(x_test, weights, y_train, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea70eb-f36e-4815-8784-ab0bc6da9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted_labels, true_labels):\n",
    "    return np.mean(predicted_labels == true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a62f5f-29c2-4d0c-ae68-e8cd823d1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy\n",
    "test_accuracy = accuracy(predicted_labels, y_test.flatten())\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f481750e-9020-4e5d-a306-483734be0010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
